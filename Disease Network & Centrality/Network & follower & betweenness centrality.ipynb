{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import csv\n",
    "import networkx as nx\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_list = ['Cardiovascular','Dementia','Diabetes','HIV','Intestinal',\n",
    "                'Kidney','Malnutrition','Maternal','Meningitis','Neonatal',\n",
    "               'Respiratory','Tuberculosis','Liver']\n",
    "\n",
    "for disease in disease_list:\n",
    "    filename = disease + '/#' + disease + '.csv'\n",
    "    df=pd.read_csv(filename,encoding='iso-8859-1')\n",
    "    \n",
    "    #select useful columns \n",
    "    network={'User name':df['screen_name'],\n",
    "        'Text':df['text'],\n",
    "        'Create time':df['created_at'],\n",
    "        'Source':df['source'],\n",
    "        'Favourite count':df['favorite_count'],\n",
    "        'Retweet count':df['retweet_count'],\n",
    "        'Hashtags':df['hashtags'],\n",
    "        'url':df['urls_url'],\n",
    "        'follower':df['followers_count'],\n",
    "        'following':df['friends_count'],\n",
    "        'location':df['location']}\n",
    "    \n",
    "    networkcsv=pd.DataFrame.from_dict(network,orient='index').transpose()\n",
    "    \n",
    "    # follower\n",
    "    follower_csv = networkcsv[['User name','follower','location','url']]\n",
    "    follower_csv = follower_csv.sort_values('follower',ascending=False)\n",
    "    follower_csv.reset_index(inplace = True)\n",
    "    follower_csv = follower_csv.drop(columns = 'index')\n",
    "    follower_csv = follower_csv.drop_duplicates(subset='User name',keep='first',inplace=False)\n",
    "    follower_csv = follower_csv.iloc[0:20]\n",
    "    follower_csv.reset_index(inplace = True)\n",
    "    follower_csv = follower_csv.drop(columns = 'index')\n",
    "    \n",
    "    follower_name = disease + '/#' + disease + 'follower.csv'\n",
    "    follower_csv.to_csv(follower_name,encoding='utf-8')\n",
    "    \n",
    "    #network\n",
    "    networktext=networkcsv['Text']\n",
    "    \n",
    "    pattern = re.compile(r'@(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mentioned =[]\n",
    "    for name1 in networktext: # Find the user who has #\n",
    "        name=re.findall(pattern,name1)\n",
    "        if name!=[]:\n",
    "            mentioned.append(name)\n",
    "        else:\n",
    "            mentioned.append(1)\n",
    "            \n",
    "    usernames=networkcsv['User name']\n",
    "    usernamess=[]\n",
    "    for i in usernames:\n",
    "        usernamess.append(i)\n",
    "        \n",
    "    mention_net ={'username':usernamess,\n",
    "         'mentioned':mentioned}\n",
    "    \n",
    "    mention_net = pd.DataFrame.from_dict(mention_net,orient ='index').transpose()\n",
    "    \n",
    "    x=0\n",
    "    test=mention_net['mentioned'] # Select the user who doesn't have #\n",
    "    droplist=[]\n",
    "    leavelist=[]\n",
    "    for tag in test:\n",
    "        if tag is 1:\n",
    "            droplist.append(x)\n",
    "        else:\n",
    "            leavelist.append(x)\n",
    "        x=x+1\n",
    "    \n",
    "    newmentioned=mention_net.drop(droplist)\n",
    "    \n",
    "    te=newmentioned['username']\n",
    "    lovelyname=[] \n",
    "    for i in te:\n",
    "        lovelyname.append(i) # Create a new name list\n",
    "        \n",
    "    tag1=newmentioned['mentioned']\n",
    "    tag2=[]\n",
    "    newuser=[]\n",
    "    x=0\n",
    "    for i in tag1:\n",
    "        for s in i:\n",
    "            tag2.append(s) # Create a new tag list\n",
    "            newuser.append(lovelyname[x]) #Create a new username with all tags\n",
    "        x=x+1\n",
    "        \n",
    "    socialnetwork={'Username':newuser,\n",
    "              'Tag':tag2}\n",
    "    \n",
    "    socialnetworkcsv=pd.DataFrame.from_dict(socialnetwork,orient ='index').transpose() #Create a new csv file\n",
    "    \n",
    "    nsocialnetworkcsv=socialnetworkcsv.set_index('Username') \n",
    "    \n",
    "    mantion_name = disease + '/#' + disease + 'mention.csv'\n",
    "    nsocialnetworkcsv.to_csv(mantion_name)\n",
    "    \n",
    "    \n",
    "    with open(mantion_name, 'r') as edgecsv: # Open the file\n",
    "        edgereader = csv.reader(edgecsv) # Read the csv     \n",
    "        edges = [tuple(e) for e in edgereader][1:] # Retrieve the data\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    print(disease,nx.info(G))\n",
    "    \n",
    "    print(disease,nx.is_connected(G))\n",
    "\n",
    "# Next, use nx.connected_components to get the list of components,\n",
    "# then use the max() command to find the largest one:\n",
    "    components = nx.connected_components(G)\n",
    "    largest_component = max(components, key=len)\n",
    "\n",
    "# Create a \"subgraph\" of just the largest component\n",
    "# Then calculate the diameter of the subgraph, just like you did with density.\n",
    "\n",
    "    subgraph = G.subgraph(largest_component)\n",
    "    diameter = nx.diameter(subgraph)\n",
    "    print(disease,\"Network diameter of largest component:\", diameter)\n",
    "    \n",
    "    layout = nx.spring_layout(G)\n",
    "    plt.figure(figsize=(150,150))\n",
    "    nx.draw_networkx(G, layout, with_lables=False,front_size=30,node_color=\"skyblue\")\n",
    "    plt.title('Network')\n",
    "    png1_name = disease + '/#'+ disease + '1.png'\n",
    "    plt.savefig(png1_name, dpi=100)\n",
    "    \n",
    "    layout = nx.spring_layout(subgraph)\n",
    "    plt.figure(figsize=(150,150))\n",
    "    nx.draw_networkx(subgraph, layout, with_lables=False,front_size=30)\n",
    "    png2_name = disease + '/#' + disease + '2.png'\n",
    "    plt.savefig(png2_name, dpi=100)\n",
    "    \n",
    "    # degree\n",
    "    degree_dict = dict(G.degree(G.nodes()))\n",
    "\n",
    "    sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)\n",
    "    degree_user=[]\n",
    "    degree_value = []\n",
    "    for d in sorted_degree:\n",
    "        #print(d)\n",
    "        degree_user.append(d[0])\n",
    "        degree_value.append(d[1])\n",
    "    \n",
    "    #betweenness\n",
    "    betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\n",
    "\n",
    "    sorted_betweenness = sorted(betweenness_dict.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    betweeness_user=[]\n",
    "    betweeness_value=[]\n",
    "\n",
    "    for b in sorted_betweenness:\n",
    "        #print(b)\n",
    "        betweeness_user.append(b[0])\n",
    "        betweeness_value.append(b[1])\n",
    "        \n",
    "    Degree_information={'Degree User':degree_user,\n",
    "             'Degree Value':degree_value}\n",
    "    Betweenness_information = {'Betweenness User':betweeness_user,\n",
    "                          'Betweenness Value':betweeness_value}\n",
    "    \n",
    "    de_informationcsv=pd.DataFrame.from_dict(Degree_information,orient='index').transpose()\n",
    "    de_name = disease + '/#'+ disease + 'degree.csv'\n",
    "    de_informationcsv.to_csv(de_name)\n",
    "\n",
    "    Be_informationcsv=pd.DataFrame.from_dict(Betweenness_information,orient='index').transpose()\n",
    "    Be_name = disease + '/#'+ disease + 'between.csv'\n",
    "    Be_informationcsv.to_csv(Be_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
